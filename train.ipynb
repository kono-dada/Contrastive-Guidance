{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from diffusion import DiffusionPipeline\n",
    "from diffusion.unet import UNet\n",
    "import os\n",
    "from diffusion.config import Config\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader: DataLoader, pipe: DiffusionPipeline, optimizer):\n",
    "    losses = []\n",
    "    size = len(dataloader.dataset)\n",
    "    pipe.unet.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X= X.cuda()\n",
    "        loss = pipe.predict_eps(X)\n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        # print loss\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f'loss: {loss:>7f}, [{current:>5d}/{size:>5d}]', end='\\r')\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.MNIST('./F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('./F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=bs, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=bs, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1-------------------------------\n",
      "loss: 0.111089, [59008/60000]\n",
      "Epoch 2-------------------------------\n",
      "loss: 0.088250, [59008/60000]\n",
      "Epoch 3-------------------------------\n",
      "loss: 0.092896, [59008/60000]\n",
      "Epoch 4-------------------------------\n",
      "loss: 0.054912, [59008/60000]\n",
      "Epoch 5-------------------------------\n",
      "loss: 0.071897, [59008/60000]\n",
      "Epoch 6-------------------------------\n",
      "loss: 0.068523, [59008/60000]\n",
      "Epoch 7-------------------------------\n",
      "loss: 0.071238, [59008/60000]\n",
      "Epoch 8-------------------------------\n",
      "loss: 0.061659, [59008/60000]\n",
      "Epoch 9-------------------------------\n",
      "loss: 0.050357, [59008/60000]\n",
      "Epoch 10-------------------------------\n",
      "loss: 0.056092, [59008/60000]\n",
      "Epoch 11-------------------------------\n",
      "loss: 0.040676, [59008/60000]\n",
      "Epoch 12-------------------------------\n",
      "loss: 0.063934, [59008/60000]\n",
      "Epoch 13-------------------------------\n",
      "loss: 0.066684, [59008/60000]\n",
      "Epoch 14-------------------------------\n",
      "loss: 0.051242, [59008/60000]\n",
      "Epoch 15-------------------------------\n",
      "loss: 0.044696, [59008/60000]\n",
      "Epoch 16-------------------------------\n",
      "loss: 0.057893, [59008/60000]\n",
      "Epoch 17-------------------------------\n",
      "loss: 0.061986, [59008/60000]\n",
      "Epoch 18-------------------------------\n",
      "loss: 0.055724, [59008/60000]\n",
      "Epoch 19-------------------------------\n",
      "loss: 0.040235, [59008/60000]\n",
      "Epoch 20-------------------------------\n",
      "loss: 0.040064, [59008/60000]\n",
      "Epoch 21-------------------------------\n",
      "loss: 0.052854, [59008/60000]\n",
      "Epoch 22-------------------------------\n",
      "loss: 0.042954, [59008/60000]\n",
      "Epoch 23-------------------------------\n",
      "loss: 0.074556, [59008/60000]\n",
      "Epoch 24-------------------------------\n",
      "loss: 0.051759, [59008/60000]\n",
      "Epoch 25-------------------------------\n",
      "loss: 0.036982, [59008/60000]\n",
      "Epoch 26-------------------------------\n",
      "loss: 0.046798, [59008/60000]\n",
      "Epoch 27-------------------------------\n",
      "loss: 0.038191, [59008/60000]\n",
      "Epoch 28-------------------------------\n",
      "loss: 0.040328, [59008/60000]\n",
      "Epoch 29-------------------------------\n",
      "loss: 0.044471, [59008/60000]\n",
      "Epoch 30-------------------------------\n",
      "loss: 0.042430, [59008/60000]\n",
      "Epoch 31-------------------------------\n",
      "loss: 0.049770, [59008/60000]\n",
      "Epoch 32-------------------------------\n",
      "loss: 0.036602, [59008/60000]\n",
      "Epoch 33-------------------------------\n",
      "loss: 0.043862, [59008/60000]\n",
      "Epoch 34-------------------------------\n",
      "loss: 0.042419, [59008/60000]\n",
      "Epoch 35-------------------------------\n",
      "loss: 0.037401, [55168/60000]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     26\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, pipe, optimizer)\u001b[0m\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 11\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# print loss\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = Config(\n",
    "    hidden_dim_list=(16, 32, 64)\n",
    ")\n",
    "\n",
    "\n",
    "pipe = DiffusionPipeline(device='cuda', config=config)\n",
    "model = pipe.unet\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "# create the folder if not exists\n",
    "if not os.path.exists(f'./exp_{timestamp}'):\n",
    "    os.makedirs(f'./exp_{timestamp}')\n",
    "# save config in json\n",
    "with open(f'./exp_{timestamp}/config.json', 'w') as f:\n",
    "    json.dump(config.__dict__, f, indent=2)\n",
    "    \n",
    "losses = []\n",
    "for t in range(epochs):\n",
    "    print(f'\\nEpoch {t+1}-------------------------------')\n",
    "    loss = train(trainloader, pipe, optimizer)\n",
    "    losses.append(loss)\n",
    "    scheduler.step()\n",
    "    # sample(model, t+1, n_classes)\n",
    "    if (t+1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f'./exp_{timestamp}/checkpoint_{t+1}.pth')\n",
    "        \n",
    "# plot losses line chart\n",
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
